{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1eJYTSKFWySWORYVUQmDbIPVU5jT0Lh1P",
      "authorship_tag": "ABX9TyPI8IAk0fX9DYbHNDxmwYIB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1290064KyoWatanabe/One/blob/main/keyword.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import sys\n",
        "#sys.path.append('/content/drive/MyDrive/ExpertSystem/')\n",
        "\n",
        "import nltk\n",
        "nltk.download('webtext')\n",
        "#from nltk.corpus import webtext   #If this does not work, comment out the above statement and use this one\n",
        "import collections\n",
        "\n",
        "def makelist(Q):     #make dataset word list\n",
        "  with open(Q,'r') as f:\n",
        "    text=f.read()\n",
        "    words = text.split()\n",
        "    word_count=collections.Counter(words)\n",
        "  with open(Q + '.wordlist','+w') as f:\n",
        "    list=[]\n",
        "    for word,count in word_count.most_common():\n",
        "      list.append(word)\n",
        "    return list\n",
        "\n",
        "def corpuslist():     #make corpus word list\n",
        "  with open('corpus.wordlist', '+w') as f:\n",
        "    list = []\n",
        "    fileids = webtext.fileids()\n",
        "    for i in range(10000):\n",
        "      list.append(webtext.words(fileids)[i])\n",
        "\n",
        "    word_count=collections.Counter(list)\n",
        "    clist = []\n",
        "    for word, count in word_count.most_common(7000):\n",
        "      f.write(word)\n",
        "      f.write(\" \")\n",
        "      f.write(str(count))\n",
        "      f.write(\"\\n\")\n",
        "      clist.append(word)\n",
        "  return clist\n",
        "\n",
        "def plist(C, Q):  #peculiar words list\n",
        "  list = []\n",
        "  for word in Q:\n",
        "    for cword in C:\n",
        "      if word == cword:\n",
        "        break\n",
        "    list.append(word)\n",
        "  return list\n",
        "\n",
        "def score(list1, list2):   #how well match Q and dataset\n",
        "  point = 0\n",
        "  for word1 in list1:\n",
        "    for word2 in list2:\n",
        "      if word1 == word2:\n",
        "        point += 1\n",
        "        break\n",
        "  return point\n",
        "\n",
        "\n",
        "def main():\n",
        "  w1 = makelist('/content/drive/MyDrive/ExpertSystem/Q dataset.txt')\n",
        "  w2 = makelist('/content/drive/MyDrive/ExpertSystem/K1 dataset.txt')\n",
        "  w3 = makelist('/content/drive/MyDrive/ExpertSystem/K2 dataset.txt')\n",
        "\n",
        "  point1 = 0\n",
        "  point2 = 0\n",
        "\n",
        "  clist = corpuslist()\n",
        "\n",
        "  P_w1 = plist(clist, w1)\n",
        "  P_w2 = plist(clist, w2)\n",
        "  P_w3 = plist(clist, w3)\n",
        "\n",
        "  point1 = score(P_w1, P_w2)\n",
        "  point2 = score(P_w1, P_w3)\n",
        "\n",
        "  print(f\"K1 point is {point1}\")\n",
        "  print(f\"K2 point is {point2}\")\n",
        "\n",
        "  if point1 > point2:   #Which is more consistent with\n",
        "    print(\"K1 is near Q\")\n",
        "    #return 0\n",
        "  else:\n",
        "    print(\"K2 is near Q\")\n",
        "    #return 1\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "   main()"
      ],
      "metadata": {
        "id": "r8S6B9uXhMc4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}